{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "PATH_REPORTS = '../reports/'\n",
    "lstm_results_path = 'test_results/LSTM_with_Attention_{asset}_test_results.csv'\n",
    "mlp_results_path =  'test_results/MLP_{asset}_test_results.csv'\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from model.evaluation import classification_report, regression_metrics, get_classification_report\n",
    "from model.config import create_experiment_configs_dummy, create_experiment_configs_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSETS = [\n",
    "    # \"PETR3.SA\", \n",
    "    # \"PRIO3.SA\", \n",
    "    # \"VALE3.SA\", \n",
    "    # \"GGBR3.SA\", \n",
    "    # \"ABCB4.SA\", \n",
    "    \"ITUB3.SA\", \n",
    "    # \"FLRY3.SA\", \n",
    "    # \"RADL3.SA\"\n",
    "    ]\n",
    "\n",
    "seq_len_list = [1,2,3,4,5,6,7,14,21,28,35,42,49,56,63,70]\n",
    "\n",
    "moving_windows = [7,14,21]\n",
    "\n",
    "dict_experiments_dummy = create_experiment_configs_dummy(ASSETS, moving_windows)\n",
    "dict_experiments_tf = create_experiment_configs_tf(ASSETS, seq_len_list, moving_windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = \"Dummy_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 49.21it/s]\n",
      "100%|██████████| 192/192 [00:03<00:00, 52.36it/s]\n"
     ]
    }
   ],
   "source": [
    "list_results = []\n",
    "\n",
    "for name, dict_experiments, path_results in [\n",
    "    ('dummy', dict_experiments_dummy, PATH_REPORTS + \"test_results/{algorithm}_{asset}_features={feature_col}__label={label_col}_test_results.csv\"),\n",
    "    (\"tf\", dict_experiments_tf, PATH_REPORTS + 'test_results/{algorithm}_{asset}_features={features}__label={label_col}__sql_len={seq_len}__scaling_method={scaling_method}_test_results.csv'),\n",
    "    \n",
    "]:\n",
    "    \n",
    "\n",
    "    for exp_name, config in tqdm(dict_experiments.items()):\n",
    "        \n",
    "\n",
    "            \n",
    "        if name == \"tf\":\n",
    "            feature_cols = config['feature_cols']\n",
    "            label_col = config['label_col']\n",
    "            seq_len = config['seq_len']\n",
    "            asset = config['asset']\n",
    "            scaling_method = config['scaling_method']\n",
    "            algorithm = config['algorithm']\n",
    "            asset = config['asset']\n",
    "            results = pd.read_csv(path_results.format(\n",
    "                algorithm = algorithm,\n",
    "                features = \"_\".join(feature_cols),\n",
    "                label_col = label_col,\n",
    "                asset = asset.replace(\".\", \"_\"),\n",
    "                scaling_method = scaling_method.__str__(),\n",
    "                seq_len = seq_len\n",
    "            ))\n",
    "            \n",
    "        elif name == 'dummy':\n",
    "            feature_cols = [config['feature_col']]\n",
    "            label_col = config['label_col']\n",
    "            asset = config['asset']\n",
    "            algorithm = \"Dummy_model\"\n",
    "            seq_len = 1\n",
    "            scaling_method = None\n",
    "            results = pd.read_csv(path_results.format(\n",
    "                algorithm = algorithm,\n",
    "                feature_col = feature_cols[0],\n",
    "                label_col = label_col,\n",
    "                asset = asset.replace(\".\", \"_\"),\n",
    "            ))\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        reg_metrics_lstm = regression_metrics(results.y_test, results.y_pred)\n",
    "        \n",
    "        y_test =  results.y_test\n",
    "        y_pred = results.y_pred\n",
    "        \n",
    "        y_test_trunc = [int(i) for i in y_test]\n",
    "        y_pred_trunc = [int(i) for i in y_pred]\n",
    "        \n",
    "        df_cr = get_classification_report(y_test_trunc, y_pred_trunc)\n",
    "        \n",
    "        df_cr = df_cr.reset_index(drop=False).rename({'index': 'class'}, axis =1 )\n",
    "        \n",
    "        for metric, value in reg_metrics_lstm.squeeze().to_dict().items():\n",
    "            new_row = {\n",
    "                'class': metric,\n",
    "                'precision': value,\n",
    "                'recall': value,\n",
    "                'f1-score': value,\n",
    "                'support': value, \n",
    "            }\n",
    "            df_cr.loc[len(df_cr)] = new_row\n",
    "        \n",
    "        df_cr['asset'] = asset\n",
    "        df_cr['feature_cols'] = str(feature_cols)\n",
    "        df_cr['label_col'] = str(label_col)\n",
    "        df_cr['seq_len'] = seq_len\n",
    "        df_cr['model'] = algorithm\n",
    "        df_cr['scaling_method'] = scaling_method\n",
    "        \n",
    "        list_results.append(df_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = pd.concat(list_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>asset</th>\n",
       "      <th>feature_cols</th>\n",
       "      <th>label_col</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>model</th>\n",
       "      <th>scaling_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>R-squared (R2)</td>\n",
       "      <td>0.724818</td>\n",
       "      <td>0.724818</td>\n",
       "      <td>0.724818</td>\n",
       "      <td>0.724818</td>\n",
       "      <td>ITUB3.SA</td>\n",
       "      <td>['past_diff_close_mean_z_score_21']</td>\n",
       "      <td>diff_close_mean_z_score_21</td>\n",
       "      <td>1</td>\n",
       "      <td>Dummy_model</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             class  precision    recall  f1-score   support     asset  \\\n",
       "13  R-squared (R2)   0.724818  0.724818  0.724818  0.724818  ITUB3.SA   \n",
       "\n",
       "                           feature_cols                   label_col  seq_len  \\\n",
       "13  ['past_diff_close_mean_z_score_21']  diff_close_mean_z_score_21        1   \n",
       "\n",
       "          model scaling_method  \n",
       "13  Dummy_model           None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results[\n",
    "    (final_results['class'] == 'R-squared (R2)') &\n",
    "    (final_results['label_col'] == 'diff_close_mean_z_score_21') &\n",
    "    (final_results['model'] == 'Dummy_model')\n",
    "    ].sort_values('f1-score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>asset</th>\n",
       "      <th>feature_cols</th>\n",
       "      <th>label_col</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>model</th>\n",
       "      <th>scaling_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>R-squared (R2)</td>\n",
       "      <td>0.816686</td>\n",
       "      <td>0.816686</td>\n",
       "      <td>0.816686</td>\n",
       "      <td>0.816686</td>\n",
       "      <td>ITUB3.SA</td>\n",
       "      <td>['diff_close_mean_z_score_21']</td>\n",
       "      <td>diff_close_mean_z_score_21</td>\n",
       "      <td>4</td>\n",
       "      <td>MLP</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>R-squared (R2)</td>\n",
       "      <td>0.816816</td>\n",
       "      <td>0.816816</td>\n",
       "      <td>0.816816</td>\n",
       "      <td>0.816816</td>\n",
       "      <td>ITUB3.SA</td>\n",
       "      <td>['diff_close_mean_z_score_21']</td>\n",
       "      <td>diff_close_mean_z_score_21</td>\n",
       "      <td>1</td>\n",
       "      <td>MLP</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>R-squared (R2)</td>\n",
       "      <td>0.818037</td>\n",
       "      <td>0.818037</td>\n",
       "      <td>0.818037</td>\n",
       "      <td>0.818037</td>\n",
       "      <td>ITUB3.SA</td>\n",
       "      <td>['diff_close_mean_z_score_21']</td>\n",
       "      <td>diff_close_mean_z_score_21</td>\n",
       "      <td>4</td>\n",
       "      <td>LSTM_with_Attention</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>R-squared (R2)</td>\n",
       "      <td>0.818499</td>\n",
       "      <td>0.818499</td>\n",
       "      <td>0.818499</td>\n",
       "      <td>0.818499</td>\n",
       "      <td>ITUB3.SA</td>\n",
       "      <td>['diff_close_mean_z_score_21']</td>\n",
       "      <td>diff_close_mean_z_score_21</td>\n",
       "      <td>3</td>\n",
       "      <td>LSTM_with_Attention</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>R-squared (R2)</td>\n",
       "      <td>0.818977</td>\n",
       "      <td>0.818977</td>\n",
       "      <td>0.818977</td>\n",
       "      <td>0.818977</td>\n",
       "      <td>ITUB3.SA</td>\n",
       "      <td>['diff_close_mean_z_score_21']</td>\n",
       "      <td>diff_close_mean_z_score_21</td>\n",
       "      <td>3</td>\n",
       "      <td>MLP</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             class  precision    recall  f1-score   support     asset  \\\n",
       "13  R-squared (R2)   0.816686  0.816686  0.816686  0.816686  ITUB3.SA   \n",
       "13  R-squared (R2)   0.816816  0.816816  0.816816  0.816816  ITUB3.SA   \n",
       "13  R-squared (R2)   0.818037  0.818037  0.818037  0.818037  ITUB3.SA   \n",
       "13  R-squared (R2)   0.818499  0.818499  0.818499  0.818499  ITUB3.SA   \n",
       "13  R-squared (R2)   0.818977  0.818977  0.818977  0.818977  ITUB3.SA   \n",
       "\n",
       "                      feature_cols                   label_col  seq_len  \\\n",
       "13  ['diff_close_mean_z_score_21']  diff_close_mean_z_score_21        4   \n",
       "13  ['diff_close_mean_z_score_21']  diff_close_mean_z_score_21        1   \n",
       "13  ['diff_close_mean_z_score_21']  diff_close_mean_z_score_21        4   \n",
       "13  ['diff_close_mean_z_score_21']  diff_close_mean_z_score_21        3   \n",
       "13  ['diff_close_mean_z_score_21']  diff_close_mean_z_score_21        3   \n",
       "\n",
       "                  model    scaling_method  \n",
       "13                  MLP              None  \n",
       "13                  MLP              None  \n",
       "13  LSTM_with_Attention  StandardScaler()  \n",
       "13  LSTM_with_Attention              None  \n",
       "13                  MLP              None  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results[\n",
    "    (final_results['class'] == 'R-squared (R2)') &\n",
    "    (final_results['label_col'] == 'diff_close_mean_z_score_21')\n",
    "    ].sort_values('f1-score').tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>asset</th>\n",
       "      <th>feature_cols</th>\n",
       "      <th>label_col</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>model</th>\n",
       "      <th>scaling_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.536742</td>\n",
       "      <td>0.536995</td>\n",
       "      <td>0.536868</td>\n",
       "      <td>963.0</td>\n",
       "      <td>ITUB3.SA</td>\n",
       "      <td>['past_diff_close_mean_z_score_21']</td>\n",
       "      <td>diff_close_mean_z_score_21</td>\n",
       "      <td>1</td>\n",
       "      <td>Dummy_model</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  precision    recall  f1-score  support     asset  \\\n",
       "7  macro avg   0.536742  0.536995  0.536868    963.0  ITUB3.SA   \n",
       "\n",
       "                          feature_cols                   label_col  seq_len  \\\n",
       "7  ['past_diff_close_mean_z_score_21']  diff_close_mean_z_score_21        1   \n",
       "\n",
       "         model scaling_method  \n",
       "7  Dummy_model           None  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results[\n",
    "    (final_results['class'] == 'macro avg') &\n",
    "    (final_results['label_col'] == 'diff_close_mean_z_score_21') &\n",
    "    (final_results['model'] == 'Dummy_model')\n",
    "    ].sort_values('f1-score').tail(199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>asset</th>\n",
       "      <th>feature_cols</th>\n",
       "      <th>label_col</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>model</th>\n",
       "      <th>scaling_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.567579</td>\n",
       "      <td>0.310273</td>\n",
       "      <td>0.312683</td>\n",
       "      <td>964.0</td>\n",
       "      <td>ITUB3.SA</td>\n",
       "      <td>['diff_close_mean_z_score_21']</td>\n",
       "      <td>diff_close_mean_z_score_21</td>\n",
       "      <td>7</td>\n",
       "      <td>MLP</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.540619</td>\n",
       "      <td>0.313280</td>\n",
       "      <td>0.315079</td>\n",
       "      <td>964.0</td>\n",
       "      <td>ITUB3.SA</td>\n",
       "      <td>['diff_close_mean_z_score_21']</td>\n",
       "      <td>diff_close_mean_z_score_21</td>\n",
       "      <td>3</td>\n",
       "      <td>MLP</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.567776</td>\n",
       "      <td>0.313739</td>\n",
       "      <td>0.318082</td>\n",
       "      <td>964.0</td>\n",
       "      <td>ITUB3.SA</td>\n",
       "      <td>['diff_close_mean_z_score_21']</td>\n",
       "      <td>diff_close_mean_z_score_21</td>\n",
       "      <td>3</td>\n",
       "      <td>MLP</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.567960</td>\n",
       "      <td>0.313852</td>\n",
       "      <td>0.318276</td>\n",
       "      <td>964.0</td>\n",
       "      <td>ITUB3.SA</td>\n",
       "      <td>['diff_close_mean_z_score_21']</td>\n",
       "      <td>diff_close_mean_z_score_21</td>\n",
       "      <td>4</td>\n",
       "      <td>LSTM_with_Attention</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.536742</td>\n",
       "      <td>0.536995</td>\n",
       "      <td>0.536868</td>\n",
       "      <td>963.0</td>\n",
       "      <td>ITUB3.SA</td>\n",
       "      <td>['past_diff_close_mean_z_score_21']</td>\n",
       "      <td>diff_close_mean_z_score_21</td>\n",
       "      <td>1</td>\n",
       "      <td>Dummy_model</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  precision    recall  f1-score  support     asset  \\\n",
       "5  macro avg   0.567579  0.310273  0.312683    964.0  ITUB3.SA   \n",
       "5  macro avg   0.540619  0.313280  0.315079    964.0  ITUB3.SA   \n",
       "5  macro avg   0.567776  0.313739  0.318082    964.0  ITUB3.SA   \n",
       "5  macro avg   0.567960  0.313852  0.318276    964.0  ITUB3.SA   \n",
       "7  macro avg   0.536742  0.536995  0.536868    963.0  ITUB3.SA   \n",
       "\n",
       "                          feature_cols                   label_col  seq_len  \\\n",
       "5       ['diff_close_mean_z_score_21']  diff_close_mean_z_score_21        7   \n",
       "5       ['diff_close_mean_z_score_21']  diff_close_mean_z_score_21        3   \n",
       "5       ['diff_close_mean_z_score_21']  diff_close_mean_z_score_21        3   \n",
       "5       ['diff_close_mean_z_score_21']  diff_close_mean_z_score_21        4   \n",
       "7  ['past_diff_close_mean_z_score_21']  diff_close_mean_z_score_21        1   \n",
       "\n",
       "                 model    scaling_method  \n",
       "5                  MLP  StandardScaler()  \n",
       "5                  MLP              None  \n",
       "5                  MLP  StandardScaler()  \n",
       "5  LSTM_with_Attention  StandardScaler()  \n",
       "7          Dummy_model              None  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results[\n",
    "    (final_results['class'] == 'macro avg') &\n",
    "    (final_results['label_col'] == 'diff_close_mean_z_score_21')\n",
    "    ].sort_values('f1-score').tail(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-tcc-tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
