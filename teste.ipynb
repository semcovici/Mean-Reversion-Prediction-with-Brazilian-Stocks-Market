{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 22:57:10.848177: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-22 22:57:10.857777: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-22 22:57:10.941481: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-22 22:57:11.027418: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-22 22:57:11.099437: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-22 22:57:11.118928: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-22 22:57:11.314925: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-22 22:57:12.799413: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_lib \n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# https://drlee.io/advanced-stock-pattern-prediction-using-lstm-with-the-attention-mechanism-in-tensorflow-a-step-by-143a2e8b0e95\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import gc\n",
    "from tensorflow.python.client import device_lib \n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Function to set random seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)     \n",
    "    tf.random.set_seed(seed) \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True # pesquisar melhor\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Setting seed\n",
    "seed=42\n",
    "set_seed(seed)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"src/\")\n",
    "from model.evaluation import create_results_df\n",
    "from model.nn_models import create_model_LSTM_with_Attention, create_model_MLP, create_model_KAN\n",
    "from model.config import create_experiment_configs_tf\n",
    "from data.preparation import load_dataset,prepare_data \n",
    "\n",
    "\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = 'data/'\n",
    "PATH_REPORTS = 'reports/'\n",
    "PATH_MODELS = 'models/'\n",
    "PATH_LOGS = \"logs\"\n",
    "\n",
    "ASSETS = [\n",
    "    \"PETR3.SA\", \n",
    "    \"PRIO3.SA\", \n",
    "    \"VALE3.SA\", \n",
    "    \"GGBR3.SA\", \n",
    "    \"ABCB4.SA\", \n",
    "    \"ITUB3.SA\", \n",
    "    \"FLRY3.SA\", \n",
    "    \"RADL3.SA\"\n",
    "    ]\n",
    "\n",
    "seq_len_list = [\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    7,14,21,28,35,42,49,56,63,70\n",
    "    ]\n",
    "\n",
    "dict_experiments = {}\n",
    "\n",
    "exp_id = 0\n",
    "\n",
    "moving_windows = [\n",
    "    7,\n",
    "    14,\n",
    "    21\n",
    "    ]\n",
    "\n",
    "                            \n",
    "dict_experiments = create_experiment_configs_tf(ASSETS, seq_len_list, moving_windows)\n",
    "\n",
    "check_if_already_exists = True\n",
    "\n",
    "def main():\n",
    "   \n",
    "    print(device_lib.list_local_devices())\n",
    "    print(\"TensorFlow Version: \", tf.__version__)\n",
    "    \n",
    "    progress = 0\n",
    "    for exp_name, config in dict_experiments.items():\n",
    "        \n",
    "        progress += 1\n",
    "        \n",
    "        print(f\"\"\"\n",
    "#####################################\n",
    "Running {progress}/{len(dict_experiments)}\n",
    "Config:\n",
    "{config}\n",
    "#####################################\n",
    "\"\"\")\n",
    "        \n",
    "        feature_cols = config['feature_cols']\n",
    "        label_col = config['label_col']\n",
    "        seq_len = config['seq_len']\n",
    "        asset = config['asset']\n",
    "        scaling_method = config['scaling_method']\n",
    "        algorithm = config['algorithm']\n",
    "        prediction_type = config['prediction_type']\n",
    "        \n",
    "\n",
    "        path_results = PATH_REPORTS + f'test_results/{algorithm}_{asset.replace(\".\", \"_\")}_features={\"_\".join(feature_cols)}__label={label_col}__sql_len={seq_len}__scaling_method={scaling_method.__str__()}_test_results.csv'\n",
    "        \n",
    "        if os.path.isfile(path_results) and check_if_already_exists:\n",
    "            print('# experiment already done')\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        dataset = load_dataset(asset, DATA_DIR)\n",
    "        X_train, X_test, y_train, y_test = prepare_data(dataset, seq_len, feature_cols, label_col, scaling_method)\n",
    "        \n",
    "        \n",
    "        if prediction_type=='regression':\n",
    "            \n",
    "            num_classes = None\n",
    "            \n",
    "            if algorithm in ['MLP', 'LSTM']:\n",
    "                callbacks = [\n",
    "                    EarlyStopping(monitor='val_r2_score', patience=10, mode='max'),\n",
    "                    # ModelCheckpoint(PATH_MODELS + f'best_model_LSTM_with_Attention_{asset.replace(\".\", \"_\")}.keras', save_best_only=True, monitor='val_r2_score'),\n",
    "                    ReduceLROnPlateau(monitor='val_r2_score', factor=0.1, patience=5, mode='max'),\n",
    "                    TensorBoard(log_dir=PATH_LOGS),\n",
    "                    CSVLogger(PATH_MODELS + f'training_log_{algorithm}_{asset.replace(\".\", \"_\")}_features={\"_\".join(feature_cols)}__label={label_col}__sql_len={seq_len}_test_results.csv')\n",
    "                ]   \n",
    "            elif algorithm == 'KAN':\n",
    "                # nao sei se Ã© necessario fazer algo aqui\n",
    "                # preencher\n",
    "                # tenho que verificar se a entrada sao arrays numpy\n",
    "                pass\n",
    "            \n",
    "            else: raise ValueError(f'Algoritmo errado selecionado para {prediction_type}')\n",
    "            \n",
    "        elif prediction_type=='classification':\n",
    "            num_classes = len(np.unique(y_train))\n",
    "            \n",
    "            if algorithm in ['MLP, LSTM']:\n",
    "                callbacks = [\n",
    "                    EarlyStopping(monitor='val_loss', patience=10, mode = 'min'),\n",
    "                    # ModelCheckpoint(PATH_MODELS + f'best_model_LSTM_with_Attention_{asset.replace(\".\", \"_\")}.keras', save_best_only=True, monitor='val_r2_score'),\n",
    "                    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5,mode = 'min'),\n",
    "                    TensorBoard(log_dir=PATH_LOGS),\n",
    "                    CSVLogger(PATH_MODELS + f'training_log_{algorithm}_{asset.replace(\".\", \"_\")}_features={\"_\".join(feature_cols)}__label={label_col}__sql_len={seq_len}_test_results.csv')\n",
    "                ]\n",
    "\n",
    "                # Convertendo os rÃ³tulos para one-hot encoding\n",
    "                y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "                y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "                \n",
    "            elif algorithm == 'KAN':\n",
    "                # preencher\n",
    "                # fazer processamento dos dados de rotulo que nao Ã© pra estar em to_categorical,\n",
    "                # mas sim em squeeze\n",
    "                # e tbm tenho que verificar se entradas sao arrays numpy\n",
    "                pass\n",
    "                \n",
    "            else: raise ValueError(f'Algoritmo errado selecionado para {prediction_type}')\n",
    "\n",
    "            \n",
    "        else: raise ValueError(f'NÃ£o existe prediction_type = {prediction_type}')\n",
    "            \n",
    "        \n",
    "        if algorithm == 'LSTM_with_Attention':\n",
    "            model = create_model_LSTM_with_Attention(\n",
    "                input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "                num_classes=num_classes\n",
    "                )\n",
    "        elif algorithm == 'MLP':\n",
    "            model = create_model_MLP(\n",
    "                input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "                num_classes=num_classes\n",
    "                )\n",
    "            \n",
    "        elif algorithm == 'KAN':\n",
    "\n",
    "            y_train = y_train.squeeze()\n",
    "            y_test = y_test.squeeze()\n",
    "\n",
    "            # Realizando o flatten das sÃ©ries de entrada\n",
    "            X_train_flatten = np.reshape(X_train, (X_train.shape[0], X_train.shape[1]*X_train.shape[2]))\n",
    "            X_test_flatten = np.reshape(X_test, (X_test.shape[0], X_test.shape[1]*X_test.shape[2]))\n",
    "\n",
    "            X_train_flatten, X_val_flatten, y_train, y_val = train_test_split(X_train_flatten, y_train,\n",
    "                                                                               test_size=0.2,\n",
    "                                                                                 random_state=seed,\n",
    "                                                                                   stratify=y_train)\n",
    "            \n",
    "            le = LabelEncoder()\n",
    "            le = le.fit(y_train)\n",
    "            y_train = le.transform(y_train)\n",
    "            y_val = le.transform(y_val)\n",
    "\n",
    "            train_input = torch.from_numpy(X_train_flatten).type(torch.float32).to(device)\n",
    "            train_label = torch.from_numpy(y_train).type(torch.long).to(device)\n",
    "\n",
    "            #print(train_input.shape)\n",
    "            \n",
    "            val_input = torch.from_numpy(X_val_flatten).type(torch.float32).to(device)\n",
    "            val_label = torch.from_numpy(y_val).type(torch.long).to(device)\n",
    "\n",
    "            test_input = torch.from_numpy(X_test_flatten).type(torch.float32).to(device)\n",
    "            test_label = torch.from_numpy(y_test).type(torch.long).to(device) # tirar talvez dps\n",
    "            \n",
    "    \n",
    "            model = create_model_KAN(\n",
    "            input_shape=X_train_flatten.shape[1], # quantidade de elementos no array unidimensional\n",
    "            num_classes=num_classes\n",
    "            )\n",
    "            \n",
    "        else: raise ValueError(f'NÃ£o existe algorithm = {algorithm}') \n",
    "        \n",
    "        #print(model.summary())\n",
    "    \n",
    "    \n",
    "        if algorithm in ['MLP', 'LSTM']:\n",
    "            model.fit(X_train, y_train, epochs=1000, batch_size=64, validation_split=0.2, callbacks=callbacks)\n",
    "\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        elif algorithm == 'KAN':\n",
    "\n",
    "            # define the loss function \n",
    "            if prediction_type=='regression':\n",
    "\n",
    "                loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "            elif prediction_type=='classification':\n",
    "\n",
    "                loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "            else: raise ValueError('PIPIPIPIP')\n",
    "\n",
    "\n",
    "            # como lidar com train_input sendo que ele Ã© um processamento de X_train, e ademais com outros\n",
    "            model.fit({'train_input': train_input, 'train_label': train_label,\n",
    "                        'test_input': val_input, 'test_label': val_label},\n",
    "                        opt=\"LBFGS\",\n",
    "                        steps=2,\n",
    "                        loss_fn=loss_fn)\n",
    "\n",
    "            y_pred = model.forward(test_input).detach()\n",
    "\n",
    "            # define the loss function \n",
    "            #if prediction_type=='classification':\n",
    "\n",
    "                #y_pred = torch.argmax(y_pred,dim=1)\n",
    "                            \n",
    "                \n",
    "            y_pred = y_pred.cpu().numpy()\n",
    "\n",
    "            print(y_pred)\n",
    "\n",
    "            # gerar as predicoes aqui, mas acho que o fit eu tenho que dar antes mesmo talvez (na parte de regressao ou classificacao)\n",
    "            # qual sera que Ã© o tipo da variavel de y_pred para MLP e LSTM? (verificar para ver se Ã© igual)\n",
    "        \n",
    "        if prediction_type == 'regression':\n",
    "\n",
    "                y_test = list(y_test.reshape(-1))\n",
    "                y_pred = list(y_pred.reshape(y_pred.shape[0]))\n",
    "\n",
    "        elif prediction_type == 'classification':\n",
    "\n",
    "            # Convertendo os rÃ³tulos verdadeiros (y_test) de one-hot encoding para rÃ³tulos de classe\n",
    "            y_test = np.argmax(y_test, axis=1)\n",
    "            # Convertendo as previsÃµes (y_pred) de probabilidades para rÃ³tulos de classe\n",
    "            y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "            if algorithm == 'KAN':\n",
    "                y_pred = le.inverse_transform(y_pred)\n",
    "\n",
    "            # Transformando os arrays em listas para criar o DataFrame de resultados\n",
    "            y_test = list(y_test.reshape(-1))\n",
    "            y_pred = list(y_pred.reshape(-1))\n",
    "        \n",
    "        #if algorithm in ['MLP', 'LSTM']:\n",
    "        \n",
    "        #    if prediction_type == 'regression':\n",
    "\n",
    "        #        y_test = list(y_test.reshape(-1))\n",
    "        #        y_pred = list(y_pred.reshape(y_pred.shape[0]))\n",
    "        #    elif prediction_type == 'classification':\n",
    "\n",
    "                # Convertendo os rÃ³tulos verdadeiros (y_test) de one-hot encoding para rÃ³tulos de classe\n",
    "        #        y_test = np.argmax(y_test, axis=1)\n",
    "                # Convertendo as previsÃµes (y_pred) de probabilidades para rÃ³tulos de classe\n",
    "        #        y_pred = np.argmax(y_pred, axis=1)\n",
    "                # Transformando os arrays em listas para criar o DataFrame de resultados\n",
    "        #        y_test = list(y_test.reshape(-1))\n",
    "        #        y_pred = list(y_pred.reshape(-1))\n",
    "                \n",
    "        #elif algorithm == 'KAN':\n",
    "            \n",
    "        #    if prediction_type == 'regression':\n",
    "\n",
    "        #        y_test = list(y_test.reshape(-1))\n",
    "                \n",
    "        #    elif prediction_type == 'classification':\n",
    "\n",
    "        #        y_test = list(y_test.reshape(-1))\n",
    "            \n",
    "            \n",
    "        #else: raise ValueError(f'NÃ£o existe prediction_type = {prediction_type}')\n",
    "            \n",
    "\n",
    "        results_df = create_results_df(y_test, y_pred)\n",
    "        \n",
    "        print(\"results in \", path_results)\n",
    "        results_df.to_csv(path_results, index = False)\n",
    "        \n",
    "        # Limpeza da sessÃ£o\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
